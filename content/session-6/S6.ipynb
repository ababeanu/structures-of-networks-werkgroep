{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "0a9e4012-c6b8-4fce-82cc-cfbbb9363d7c",
      "cell_type": "markdown",
      "source": "# Structures of Networks - workgroup session 6\n\nThe structure of this notebook follows that of the associated problem sheet.\nCode blocks (cells) are already available for (sub)problems that involve coding, but you can always add more.\nSome of these code blocks contain coding-related tips, in the form of comments.",
      "metadata": {}
    },
    {
      "id": "9b4191e3-7c0a-446d-b9eb-b36302b93ad7",
      "cell_type": "markdown",
      "source": "## 1.a.",
      "metadata": {}
    },
    {
      "id": "a199e99c-aa3f-409a-929b-046ac17d2ce2",
      "cell_type": "code",
      "source": "import networkx as ntx\nimport random as rn\nimport numpy as np\nimport math as mt\nimport matplotlib.pyplot as plt\n\nrn.seed(1)\nnp.random.seed(1)\n\n# randomly generates a list of feature vectors (LFV), containing n vectors of F entries each, where each entry is a binary random (unbiased) variable\ndef random_LFV(n, F):\n    x = []    \n    for i in range(0, n):\n        xi = []\n        for f in range(0, F):\n            xi.append(rn.randint(0, 1))\n        x.append(xi)\n        \n    return x\n\n# randomly generates a list of feature vectors with categories (LFVC), containing n vectors of F entries (feature/variable values)\n# the number of values that each feature may take matches the number of categories, specified by argument C\n# each category has un underlying, latent feature vector, populated by one value, constant across features and distinct from the (constant) values associated to other latent vectors\n# each vector is randomly assigned to one category and generated as a partial copy of that category's latent vector\n# for each vector, the values of D randomly selected features are copied from its category's latent vector, while the other are generated randomly\n# returns the list of generated feature vectors, along with a list of associated integers encoding the ground-truth partition - each entry identifies the a-priori category of the vector\ndef random_LFVC(n, F, C, D):\n    # list of feature vectors\n    x = []\n    # ground truth partition, containing one integer for each feature vector\n    gtp = [] \n\n    for i in range(0,n):\n        xi = []\n        # picking category\n        c = rn.choice(range(0,C))\n        gtp.append(c)\n        # sampling without replacement, using rn.sample(), D features that are to be copied from the category's latent vector\n        lf = sorted(rn.sample(range(0,F), D))\n        for a in range(0,F):\n            genrand = False\n            if(len(lf) > 0):\n                if(a == lf[0]):\n                    xi.append(c)\n                    del lf[0]\n                else:\n                    genrand = True\n            else:\n                genrand = True\n            if(genrand):\n                xi.append(rn.choice(range(0,C)))\n        x.append(xi)\n    \n    return x, gtp\n\n# applies a joint sorting operation on data compliant with the output of random_LFVC function above\n# carries out sorting for increasing values of the ground truth partition (gtp) list\n# returns the consistently sorted counterparts of the set of feature vectors (x) and ground truth partition (gtp), along with the list of vector ids (consistent with the initial ordering)\ndef joint_sort(x, gtp):\n\n    ids = range(0,n)\n\n    # assembling list of tuples\n    lt = []\n    for i in range(0,n):\n        lt.append((x[i], gtp[i], ids[i]))\n\n    # sorting the list of tuples according to gtp value\n    lt_s = sorted(lt, key=lambda t: t[1])  \n\n    # unpacking the sorted list of tuples\n    x_s = []\n    gtp_s = []\n    ids_s = []\n    for i in range(0,n):\n        (x_i, gtp_i, ids_i) = lt_s[i]\n        x_s.append(x_i)\n        gtp_s.append(gtp_i)\n        ids_s.append(ids_i)\n    \n    return x_s, gtp_s, ids_s\n\n# computes the (Hamming) similarity between two (binary) vectors of equal lenghts\ndef similarity(x1, x2):\n    F = len(x1)\n    nmatch = 0.0\n    for a in range(0, F):\n        nmatch += int(x1[a] == x2[a])\n    return float(nmatch)/F\n\n# computes the lmbd-adjusted (Hamming similarity between two (binary) vectors of equal lengths\ndef adjusted_similarity(x1, x2, lmbd1, lmbd2):\n    return (similarity(x1, x2))**(lmbd1*lmbd2)\n    \n\n# generates a random graph from a list of feature vectors x, using a lmbd-power-adjusted Hamming similarity, which is interpreted as a link probability\n# here, lmdb (lambda) is a list of positive-real values, one for each of the feature vectors in x (and thus for each of the nodes in the graph being generated) \ndef LFV_graph(x, lmbd):\n    n = len(x)\n    G = ntx.empty_graph(n)\n    for i in range(0, n-1):\n        for j in range(i+1, n):\n            # probability of generating link (i,j):\n            p = adjusted_similarity(x[i], x[j], lmbd[i], lmbd[j])\n            r = rn.random()\n            if(r < p):\n                ntx.add_path(G, [i,j])\n    return G\n\n# computes the the mean of the lmbd-adjusted (Hamming) similarities between all pairs of feature vectors in x\n# this is equivalent to the expected network density, given x and lmbd\ndef mean_adjusted_similarity(x, lmbd):\n    sum = 0.0\n    n = len(x)\n    for i in range(0, n-1):\n        for j in range(i+1, n):\n            sum += adjusted_similarity(x[i], x[j], lmbd[i], lmbd[j])\n    return sum*2.0/n/(n-1)\n\n# computes the expectation value of the degree of node i, given x and lmbd\ndef expected_degree(x, lmbd, i):\n    sum = 0.0\n    for j in range(0, len(x)):\n        if(j != i):\n            sum += adjusted_similarity(x[i], x[j], lmbd[i], lmbd[j])\n    return sum\n\n# computes area under the line segment between points c1, c2, where each point is encoded as a 2D coordinate pair (tuple)\ndef slice_area(coord1, coord2):\n    (x1, y1) = coord1\n    (x2, y2) = coord2\n    return (y1+y2)*(x2-x1)/2\n\n# computes area under a sequence of line segments defined by coords, which is a list of coordinate pairs\n# the l'th segment goes between coordinate pairs c[l] and c[l+1]\ndef combined_area(coords):\n    A = 0.0\n    for l in range(0,len(coords)-1):\n        A += slice_area(coords[l], coords[l+1])\n    return A\n\n# adjusts the y-components of all coordinate pairs in coords so that the latter can be interprted as a (properly normalized) probability density function with a piecewise-linear shape\n# the coordinates have to be sorted so that the x-components are strictly increasing\ndef normalize(coords):\n    A = combined_area(coords)\n    for l in range(0, len(coords)):\n        (x,y) = coords[l]\n        coords[l] = (float(x), float(y)/A)\n    return coords\n\n# generates a random number sampled from a distribution with a density function that takes a piecewise-linear shape specified by coordinate (x,y) pairs in coords list\n# each y-entry corresponds to the probability density for the respective x-entry\n# the l'th segment of the density function goes between coordinate pairs c[l] and c[l+1]\n# the coordinates have to be sorted so that the x-components are strictly increasing\n# the y-coordinates are automatically rescaled, by the same factor, in order to ensure that the distribution is normalized  \ndef rand_piecewise(coords):\n\n    coords = normalize(coords)\n    \n    r = rn.random()\n    rr = -1.0\n    \n    searching = True\n    l = 0\n    \n    while(searching):\n        A = slice_area(coords[l], coords[l+1])\n\n        if(r <= A):\n            searching = False\n            (x1, y1) = coords[l]\n            (x2, y2) = coords[l+1]\n            a = (y2-y1)/(x2-x1)\n            b = (x2*y1 - x1*y2)/(x2-x1)\n            if(a == 0.0):\n                rr = x1 + r/y1\n            else:\n                aa = a\n                bb = (b - a*x1 + y1)\n                cc = - (x1*(b+y1) + 2*r)\n                rr = (- bb + (bb**2 - 4*aa*cc)**(0.5))/(2.0*aa)\n        else:\n            r -= A\n\n        l += 1\n        \n        if(l == len(coords)-1):\n            searching = False\n\n    return rr\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "09eec76a-b7de-43fc-b3f5-93b808c7717d",
      "cell_type": "markdown",
      "source": "## 1.b",
      "metadata": {}
    },
    {
      "id": "f035a82e-9598-4024-b8f9-e8bfe6bfcb80",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}